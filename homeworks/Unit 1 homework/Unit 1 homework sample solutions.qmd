---
title: "Unit 1 homework sample solutions"
author: "Anonymous"
date: "1/19/2025"
output:
  html_document:
    toc: true
subtitle: DKU Stats 101 Spring 2025 Session 3
format: 
  html:
    embed-resources: true
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)

artdata <- read.csv("artdata.cleaned.csv")
```

![](art.jpg)


## Introduction

## Question 1: Describing your data (10 points)

### 1a. Where is this data from?

For this dataset, describe the data according to the five Ws & *how* defined in the textbook Chapter 1.2. What are some possible problems with the *who* and *what* of the dataset?

The original dataset can be found [here](https://github.com/jasonshi10/art_auction_valuation).

- `Who`: paintings that have been auctioned
- `What`: price of paintings sold, other physical characteristics of the paintings
- `When`: scraped from a website in 2018, years sold vary
- `Where`: various art auction houses
- `Why`: to analyze the features of a painting that predict the price
- `How`: scraped by github user ahmedhosny and cleaned up by github user jasonshi10, data scraped from website artsalesindex

> Possible problems: 

It is not clear from the github documentation which cases were scraped, there could be some selection bias in both what was scraped (maybe only some types of cases were scraped) and in the selection of art houses the art website monitors. For the `what`, it also is not clear how some of the features of the paintings were calculated in the rows - presumably it was done by some type of machine learning algorithm.  

### 1b. What are the variable types?

For the following variables, please list the variable type as defined in the textbook Chapter 1.3:

- `artist`: either identifier or categorical
- `country`: categorical 
- `yearOfBirth`: either identifier, quantitative, or categorical
- `name`: identifier
- `year`: either identifier or quantitative
- `ageOfPaiting`: quantitative
- `price`: quantitative
- `material`: categorical
- `height`: quantitative
- `dominantColor`: categorical

## Question 2: Displaying and describing the data (15 points)

For the moment, we are going to focus on paintings by Chinese artists. You can create a subset of your data using the `filter()` verb as you learned in the DataCamp lab. 

### 2a. Filtering your data

Using the `filter()` verb as described in the DataCamp lab, make a subset of your data that only includes art from Chinese artists. Show the code you used to make the subset using the `#| echo: true` code block option.

```{r}
#| label: q2a
#| echo: true

artdata.chinese <- artdata %>% 
  filter(country=="Chinese")
```


### 2b. Investigating height

Using the Think-Show-Tell framework from the textbook (example on page 71), investigate the distribution of the height of the Chinese paintings

Note: for this question and all other Think sections in the homework, you do not need to report the W's of the data (you have already completed this in Q1)

> Think

1. I want to summarize the distribution of heights of Chinese paintings
2. The data are height measurements of paintings from China contained in the dataset. The units are inches.
3. Since we are reviewing the distribution of one quantitative variable, a histogram is the most appropriate display.

> Show

```{r}
#| label: fig-q2b
#| echo: false
#| warning: false
#| fig-cap: "Histogram of height of Chinese art"
#| fig-subcap: 
#|      - "Original"
#|      - "Transformed"

ggplot(artdata.chinese, aes(x=height)) +
  geom_histogram(fill="blue", color="black", bins=15) + 
  labs(x="Height in in.")

ggplot(artdata.chinese, aes(x=log(height))) +
  geom_histogram(fill="red", color="black", bins=15) +
  labs(x="Log height in in.")
```

```{r}
#| label: tbl-q2ba
#| echo: false
#| tbl-cap: "Relevant statistics of variable: height"

height.fivenum <- fivenum(artdata.chinese$height)
height.sumdata <- append(height.fivenum, length(!is.na(artdata.chinese$height)), after=0)
height.sumdata <- append(height.sumdata, sd(artdata.chinese$height, na.rm=TRUE), after=1)
height.sumdata <- append(height.sumdata, mean(artdata.chinese$height, na.rm=TRUE), after=2)

names<-c("Count", "Std Dev", "Mean", "Min", "25%", "Median", "75%", "Max")

height.sumdata.table <- data.frame(names, height.sumdata)

kbl(height.sumdata.table, col.names = c("Statistic", "Value"), digits=2) %>% 
  kable_styling()
```

```{r}
#| label: tbl-q2bb
#| echo: false
#| tbl-cap: "Possible outliers of the variable: height (inches > 130)"

artdata.chinese %>% 
  filter(height > 130) %>% 
  select(c(artist, name, year, height)) %>% 
  kbl(col.names = c("Artist", "Name", "Year", "Height")) %>% 
  kable_styling()
```


The data appears to be right skewed. There appears to be a handful of suspicious outliers, but, on investigation, the values for height of each of these works appear geniune and therefore is no strong reason to exclude them. 

> Tell

After log transforming the data, the outliers no longer appear to be so serious. For the untransformed data, the mean and median are relatively close, though the mean is a little higher, likely due to the skew. The data is unimodal, right skewed, with a mean of `r round(mean(artdata.chinese$height, na.rm=TRUE), 2)`. Based on the data, we can expect that the height of each Chinese artwork will vary from the mean by an average of about `r round(sd(artdata.chinese$height, na.rm=TRUE), 2)` (the standard deviation). 

In more meaningful terms, the average artwork size height is about the size of three sheets of paper stacked on top of each other, which seems about normal considering how art paintings are usually produced. There is some variation, the standard deviation indicates that the size may vary by up to two sheets of paper worth of height, on average. The IQR is even larger, indicating a wide range of heights in the data. The outliers are more modern pieces of art that may be some type of more experimental art.

### 2c. Investigating width

Using the Think-Show-Tell framework from the textbook, investigate the distribution of the width of the Chinese paintings

> Think 

1. I want to summarize the distribution of the width of Chinese paintings
2. The data are width measurements of paintings from China contained in the dataset. The units are inches.
3. Since we are reviewing the distribution of one quantitative variable, a histogram is the most appropriate display.

> Show 

```{r}
#| label: fig-q2c
#| echo: false
#| warning: false
#| fig-cap: "Histogram of height of Chinese art"
#| fig-subcap: 
#|      - "Original"
#|      - "Transformed"

ggplot(artdata.chinese, aes(x=width)) +
  geom_histogram(fill="blue", color="black", bins=15) + 
  labs(x="Width in in")

ggplot(artdata.chinese, aes(x=log(width))) +
  geom_histogram(fill="red", color="black", bins=15) +
  labs(x="Log width in in")
```

```{r}
#| label: tbl-q2ca
#| echo: false
#| tbl-cap: "Relevant statistics of variable: width"

width.fivenum <- fivenum(artdata.chinese$width)
width.sumdata <- append(width.fivenum, length(!is.na(artdata.chinese$width)), after=0)
width.sumdata <- append(width.sumdata, sd(artdata.chinese$width, na.rm=TRUE), after=1)
width.sumdata <- append(width.sumdata, mean(artdata.chinese$width, na.rm=TRUE), after=2)

names<-c("Count", "Std Dev", "Mean", "Min", "25%", "Median", "75%", "Max")

width.sumdata.table <- data.frame(names, width.sumdata)

kbl(width.sumdata.table, col.names = c("Statistic", "Value"), digits=2) %>% 
  kable_styling()
```

```{r}
#| label: tbl-q2cb
#| echo: false
#| tbl-cap: "Possible outliers of the variable: width (inches > 200)"

artdata.chinese %>% 
  filter(width > 200) %>% 
  select(c(artist, name, year, width)) %>% 
  kbl(col.names = c("Artist", "Name", "Year", "Width")) %>% 
  kable_styling()
```

The data for width is also very right skewed with a handful of very distant outliers. One of the outliers was also an outlier in the height investigation (indicating a very large painting) and the other is a very long ink scroll. Both appear to be genuine measurements.

> Tell

A log transformation makes the distribution nearly perfectly symmetric, indicating that the data-generating process is probably logrithmic. In untransformed terms, the distribution is right skewed and unimodal, with a mean of `r round(mean(artdata.chinese$width, na.rm=TRUE), 2)`. Based on the data, we can expect that the width of each Chinese artwork will vary from the mean by an average of `r round(sd(artdata.chinese$width, na.rm=TRUE), 2)`.

In this case, the average width is a little smaller than the average height, at about 2.5 sheets of paper wide, on average. The standard deviation is actually nearly the same as the mean, in part due to the extreme outliers, but even the IQR is about 20 inches, indicating that there is significant variability in width, though less so compared to height. The large outlier indicates that some paintings may be primarily horizontally oriented and others primarily vertically oriented, which may account for the large amount of variation.

### 2d. Thinking about your results

Consider the results of 2b. and 2c. together. What can we understand about Chinese art from viewing the distribution of these two variables?

> Answers will vary here, good quality effort to interpret investigation of this question is required.

## Question 3: Relationships between categorical variables - American and Chinese artists and oil vs. ink. (15 points)

### 3a. Recoding your data

Using the `mutate()` verb and the `case_when()` verb combined with `grepl()`, create two new variables. The first is `material.type` and the second is `us.china`. The first variable should recode material to be either `Oil`, `Ink`, or `Other`, depending on whether the original values of `material` contained either the words `oil` or `ink`. The second variable should make a similar transformation to `country` where you recode the variable to be either `American`, `Chinese`, or `Other`. Show the code you used to make the new variables using the `#| echo:` true code block option.

Hint 1: you can see some examples of `case_when()` and `grepl()` [here](https://dplyr.tidyverse.org/reference/case_when.html)and [here](https://rud.is/b/2017/03/10/making-a-case-for-case_when/) .

Hint 2: make sure to use the `ignore.case=TRUE` option in `grepl()`

```{r}
#| label: q3a
#| echo: true
#| warning: false

artdata.uschina <- artdata %>% 
  mutate(material.s = case_when(grepl("oil", 
                                      material, 
                                      ignore.case = TRUE) ~ "Oil",
                                grepl("ink", 
                                      material, 
                                      ignore.case = TRUE) ~ "Ink",
                                TRUE ~ "Other"),
         country.s = case_when(country == "American" ~ "American",
                               country == "Chinese" ~ "Chinese",
                               TRUE ~ "Other"))
```


### 3b. Investigating the categorical relationship between `us.china` and `material.type`

Investigate the relationship between `us.china` and `material.type`

Hint 3: you can see an example of some ways to display this information [here](http://analyticswithr.com/contingencytables.html)

> Think 

> Show 

```{r}
#| label: tbl-q3b
#| echo: false
#| tbl-cap: "Contingency table of origin vs. material"
#| tbl-subcap: 
#|    - "Count totals"
#|    - "Percent totals"

artdata.uschina.table <- artdata.uschina %>% 
  mutate(`Material` = material.s,
         `Country` = country.s)

artdata.uschina.table %>% 
  tabyl(`Material`, `Country`) %>%
  adorn_totals(c("row", "col")) %>% 
  adorn_title("combined") %>%
  kbl() %>% 
  kable_styling()

artdata.uschina.table %>% 
  tabyl(`Material`, `Country`) %>%
  adorn_totals(c("row", "col")) %>%
  adorn_percentages("col") %>% 
  adorn_pct_formatting(rounding = "half up", digits = 0) %>%
  adorn_title("combined") %>%
  kbl() %>% 
  kable_styling()
```


> Tell

### 3c.Thinking about your results

Think carefully about why you have observed this result and provide some additional information about what this investigation means for understanding this dataset and art in general.

> Answers will vary here, good quality effort to interpret investigation of this question is required.

## Question 4: Comparing groups (15 points)

### 4a. Recoding your data

Similar to the previous question, create a new variable called `famous.countries` that recodes country to be either `American`, `French`, `Italian` and `Spanish`. Mark art from all other countries as `NA` (the code that stands for missing or not available in R). Additionally, create a new variable called `area` that is a calculation of the area of the art (height times width). Show the code you used to make the new variables using the `#| echo:` true code block option. 

```{r}
#| label: q4a
#| echo: true

artdata.famous.c <- artdata %>% 
  mutate(country.f = case_when(country=="American" ~ "American",
                               country=="French" ~ "French",
                               country=="Italian" ~ "Italian",
                               country=="Spanish" ~ "Spanish",
                               TRUE ~ NA)) %>% 
  mutate(area = height*width) %>% 
  filter(!is.na(country.f))
```


### 4b. Compare the groups of countries on the variable `price`

> Think 

> Show 

```{r}
#| label: q4b
#| echo: false
#| fig-cap: "Comparing distribution of price across select countries"
#| fig-subcap: 
#|     - "Original"
#|     - "Transformed"

ggplot(artdata.famous.c, aes(x=price, y=country.f)) +
  geom_boxplot(fill="blue", color="black") +
  labs(y="Country", x="Price in USD")

ggplot(artdata.famous.c, aes(x=log(price), y=country.f)) +
  geom_boxplot(fill="red", color="black") +
  labs(y="Country", x="Log of price in USD")
```

> Tell

### 4c. Compare the groups of countries on the variable `area`

> Think 

> Show 

```{r}
#| label: q4c1
#| echo: false

ggplot(artdata.famous.c, aes(x=area, y=country.f)) +
  geom_boxplot(fill="blue", color="black") +
  labs(y="Country", x="Area in sq cm")
```

```{r}
#| label: q4c2
#| echo: false
#| tbl-cap: "Outiers for variable: area"

artdata.famous.c %>% 
  filter(area > 150000) %>% 
  select(c(artist, country, name, height, width, area)) %>% 
  kbl() %>% 
  kable_styling()
```


```{r}
#| label: q4c3
#| echo: false
#| fig-cap: "Comparing distribution of area across select countries"
#| fig-subcap: 
#|     - "Original"
#|     - "Transformed"

artdata.famous.c <- artdata.famous.c %>% 
  filter(area < 200000)

ggplot(artdata.famous.c, aes(x=area, y=country.f)) +
  geom_boxplot(fill="blue", color="black") +
  labs(y="Country", x="Area in sq cm")

ggplot(artdata.famous.c, aes(x=log(area), y=country.f)) +
  geom_boxplot(fill="red", color="black") +
  labs(y="Country", x="Log of area in sq cm")
```

> Tell

### 4d. Thinking about your results

Consider the results of 4b. and 4c. together. What can we learn about the differences in art between the countries? What do you think causes these differences or similarities? How would you confirm your guess as to the cause of the differences/similarities?

> Answers will vary here, good quality effort to interpret investigation of this question is required.

## Question 5: Considering deviations (10 points)

### 5a. Selecting your data

Pick three years of paintings to investigate whether the brightness of paintings has changed over time. You are free to pick any three years but you should pick years that correspond to different periods in art history. State the three years and justify your selection.

> Many possible options here, in this example I will use 1888, 1920, and 1950. Need some justification for the year choice.

### 5b. Finding the average

Calculate the average brightness for each of the three years. Show your code using the `#| echo:` true code block option. 

```{r}
#| label: q5b
#| echo: true
#| tbl-cap: "Average brightness by year"

artdata %>% 
  filter(year==1888 | year==1920 | year==1950) %>% 
  group_by(year) %>% 
  summarize(mean.brightness = mean(brightness, na.rm=TRUE)) %>% 
  mutate(Year = as.character(year),
         Brightness = round(mean.brightness, 2)) %>% 
  select(Year, Brightness) %>% 
  kbl %>% 
  kable_styling()
```


### 5c. Normalizing the data

Find how many $z$ units each of the averages for the years are away from the overall mean of brightness and interpret your results. 

> Think 

> Show 

```{r}
#| label: q5c
#| tbl-cap: "Z score of the difference in brightness"
#| echo: false

# Calculate overall mean
mean.b <- c("Mean overall", mean(artdata$brightness, na.rm=TRUE), "")
sd.b <- c("SD overall", sd(artdata$brightness, na.rm=TRUE), "")

# Calculate z scores
z.table <- artdata %>% 
  filter(year==1888 | year==1920 | year==1950) %>% 
  group_by(year) %>% 
  summarize(mean = mean(brightness),
            z.score = ((mean(brightness) - 
                         as.numeric(mean.b[2]))) / 
              as.numeric(sd.b[2])) %>% 
  mutate(year = as.character(year),
         mean = as.character(round(mean, 2)),
         z.score = as.character(round(z.score, 2)))

# Convert overall mean and sd to rounded number
mean.b[2] <- as.character(round(as.numeric(mean.b[2]), 2))
sd.b[2] <- as.character(round(as.numeric(sd.b[2]), 2))

# Add overall mean and sd to table
z.table <- rbind(z.table, mean.b)
z.table <- rbind(z.table, sd.b)

z.table %>% 
  kbl(col.names=c("Year", "Mean", "Z Score")) %>% 
  kable_styling()
```


> Tell

### 5d. Thinking about your results

What are some of the implications of your findings with regard to the motivation of this question? What are some of the limitations of this analysis? What other kind of analysis would you like to do to answer this question?

> Answers will vary here, good quality effort to interpret investigation of this question is required.

## Question 6: Your own investigation (15 points)

### 6a. Selecting your own question

Similar to the previous questions, think of your own question that you would like to ask of the data. Use the Think-Show-Tell procedure to conduct your investigation. Think deeply about what your result means. 

> Think 

> Show 

> Tell

> Answers will vary here, good quality effort to interpret investigation of this question is required.

### 6b. In summary

Sum up everything that you have learned in this investigation. Do not simply repeat/rephrase your previous results but try to say something larger that synthesizes the results together to draw a more meaningful general conclusion.

> Need to think deeply about what information this dataset provides for full points.